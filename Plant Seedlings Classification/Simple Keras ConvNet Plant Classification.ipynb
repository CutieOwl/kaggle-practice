{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simpler model of Plant Seedling Classification than Transfer Learning with Xception\n",
    "Because transfer learning was confusing, I'll be trying a simpler model using just keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "\n",
    "# Import plotting for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "plt.rcParams['font.size'] = 16\n",
    "#from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import seaborn as sns\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import random\n",
    "import itertools\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"/utils/DLWorkspace-Utils/keras-multiprocess-image-data-generator\")\n",
    "#import tools.image as T\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix # for the confusion matrix\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the dataset\n",
    "First, we locate our data at the correct directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/kaggle/competitions/plant-seedlings-classification/train\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/kaggle/competitions/plant-seedlings-classification/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "print(train_dir)\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "#sample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the categories we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "NUM_CATEGORIES = len(CATEGORIES)\n",
    "IMAGE_SIZE = 70 # pixel height and width of each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of files we have per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-grass 211 images\n",
      "Charlock 312 images\n",
      "Cleavers 230 images\n",
      "Common Chickweed 489 images\n",
      "Common wheat 177 images\n",
      "Fat Hen 380 images\n",
      "Loose Silky-bent 524 images\n",
      "Maize 177 images\n",
      "Scentless Mayweed 413 images\n",
      "Shepherds Purse 185 images\n",
      "Small-flowered Cranesbill 397 images\n",
      "Sugar beet 308 images\n",
      "\n",
      "Total Number of Training images: 3803\n"
     ]
    }
   ],
   "source": [
    "TOTAL_PICS = 0\n",
    "for category in CATEGORIES:\n",
    "    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))\n",
    "    TOTAL_PICS += len(os.listdir(os.path.join(train_dir, category)))\n",
    "print(\"\\nTotal Number of Training images: %s\" % TOTAL_PICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_train(filepath, size):\n",
    "    img = image.load_img(os.path.join(train_dir, filepath), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 760 is out of bounds for axis 0 with size 760",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8b37f80cc249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mtrain_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mvalid_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mvalid_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_count\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mvalid_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 760 is out of bounds for axis 0 with size 760"
     ]
    }
   ],
   "source": [
    "# Let's split our train and validation tests 80/20.\n",
    "TRAIN_PICS = int(TOTAL_PICS * 0.8)\n",
    "VALID_PICS = int(TOTAL_PICS * 0.2)\n",
    "train_x = np.zeros((TRAIN_PICS, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "train_y = np.zeros((TRAIN_PICS))\n",
    "valid_x = np.zeros((VALID_PICS, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "valid_y = np.zeros((VALID_PICS))\n",
    "train_count = 0\n",
    "valid_count = 0\n",
    "for category_id, category in enumerate(CATEGORIES):\n",
    "    for file in os.listdir(os.path.join(train_dir, category)):\n",
    "        filepath = os.path.join(category, file)\n",
    "        img = read_img_train(filepath, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        # randomly put images in the train or validation set\n",
    "        if train_count < TRAIN_PICS:\n",
    "            if random.randint(0, 9) < 8:\n",
    "                train_x[train_count] = img/255\n",
    "                train_y[train_count] = category_id\n",
    "                train_count += 1\n",
    "            else:\n",
    "                if valid_count < VALID_PICS:\n",
    "                    valid_x[valid_count] = img/255\n",
    "                    valid_y[valid_count] = category_id\n",
    "                    valid_count += 1\n",
    "                else:\n",
    "                    train_x[train_count] = img/255\n",
    "                    train_y[train_count] = category_id\n",
    "                    train_count += 1\n",
    "        else:\n",
    "            valid_x[valid_count] = img/255\n",
    "            valid_y[valid_count] = category_id\n",
    "            valid_count += 1\n",
    "#train = pd.DataFrame(train, columns=['file', 'category_id', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print our training and validation sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train_x shape: \" + str(train_x.shape))\n",
    "print(\"Train_y shape: \" + str(train_y.shape))\n",
    "plt.imshow(train_x[0])\n",
    "plt.show()\n",
    "print(\"Category: \" + str(train_y[0]))\n",
    "\n",
    "print(\"Validation set\")\n",
    "print(\"Valid_x shape: \" + str(valid_x.shape))\n",
    "print(\"Valid_y shape: \" + str(valid_y.shape))\n",
    "plt.imshow(valid_x[0])\n",
    "plt.show()\n",
    "print(\"Category: %s\" % str(valid_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_test(filepath, size):\n",
    "    img = image.load_img(os.path.join(test_dir, filepath), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PICS = len(os.listdir(test_dir))\n",
    "test = np.zeros((TEST_PICS, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "test_ids = []\n",
    "count = 0\n",
    "for file in os.listdir(test_dir):\n",
    "    img = read_img_test(file, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    test[count] = img/255\n",
    "    test_ids.append(file) # Images' ids\n",
    "    count += 1\n",
    "#train = pd.DataFrame(train, columns=['file', 'category_id', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print our test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test's shape: %s\" % str(test.shape))\n",
    "plt.imshow(test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for the actual model!\n",
    "For now, I've just used Mehad Aria's modification of a VGG16 Net. I will need to update this to a more complicated model soon.\n",
    "\n",
    "I was originally using Andrew Ng's example of a very simple Keras network, but that ended up being TOO simple and there was very high bias, causing the neural network to not improve at all and stay at an accuracy of about 0.05-0.08 (not very good).\n",
    "\n",
    "The code for Andrew Ng's Keras network is as follows:\n",
    "```python\n",
    "    # The actual layers of the NN\n",
    "    ## Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    ## CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    ## FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(NUM_CATEGORIES, activation='sigmoid', name='fc')(X)\n",
    "```\n",
    "\n",
    "However, I am hoping that a more complex neural network will do a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlantConv2DModel(input_shape):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # The actual layers of the NN\n",
    "    X = Conv2D(filters=64, kernel_size=(5, 5), input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), activation='relu')(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=64, kernel_size=(5, 5), activation='relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv2D(filters=128, kernel_size=(5, 5), activation='relu')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=128, kernel_size=(5, 5), activation='relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Conv2D(filters=256, kernel_size=(5, 5), activation='relu')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=256, kernel_size=(5, 5), activation='relu')(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    X = Dense(256, activation='relu')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(256, activation='relu')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(NUM_CATEGORIES, activation='softmax')(X)\n",
    "    \n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='PlantConv2DModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "plantModel = PlantConv2DModel(train_x.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model (I'm using Adam optimizer and categorical_crossentropy loss for now)\n",
    "plantModel.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a summary of our model just to know what it's doing\n",
    "plantModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training set (I'll just use 20 epochs and batches of size 75 for now)\n",
    "one_hot_train_y = to_categorical(train_y)\n",
    "print(str(train_x.shape))\n",
    "print(str(train_y.shape))\n",
    "print(str(one_hot_train_y.shape))\n",
    "plantModel.fit(train_x, one_hot_train_y, epochs=20, batch_size= 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "one_hot_valid_y = to_categorical(valid_y)\n",
    "preds = plantModel.evaluate(valid_x, one_hot_valid_y, batch_size= 75)\n",
    "\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Validation Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do a confusion matrix to help us understand where we went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "pred_valid_y_raw = plantModel.predict(valid_x)\n",
    "pred_valid_y = np.argmax(pred_valid_y_raw, axis = 1) \n",
    "true_valid_y = np.argmax(one_hot_valid_y, axis = 1) \n",
    "\n",
    "# confusion matrix\n",
    "confusionMTX = confusion_matrix(true_valid_y, pred_valid_y) \n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusionMTX, classes = CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally time for testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = plantModel.predict(test)\n",
    "\n",
    "# Write prediction result to a file\n",
    "pred = np.argmax(test_preds, axis=1)\n",
    "predStr = [CATEGORIES[c] for c in pred]\n",
    "\n",
    "result = {'file':test_ids, 'species':predStr}\n",
    "result = pd.DataFrame(result)\n",
    "result.to_csv(\"Prediction.csv\",index=False)\n",
    "print('Prediction result saved as Prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
